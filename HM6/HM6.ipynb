{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro ML Homework 6\n",
    "## Name: Jaskin Kabir\n",
    "## Student ID: 801186717\n",
    "Github: https://github.com/jaskinkabir/Intro_ML/tree/main/HM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "path = 'housing.csv'\n",
    "housing = pd.DataFrame(pd.read_csv(path))\n",
    "\n",
    "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "\n",
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'yes': 1, 'no': 0, 'unfurnished': 0, 'semi-furnished': 1, 'furnished': 2})\n",
    "\n",
    "# Applying the function to the housing list\n",
    "housing[varlist] = housing[varlist].apply(binary_map)\n",
    "housing.head()\n",
    "\n",
    "df_train, df_test = train_test_split(housing, train_size=0.8, test_size=0.2, random_state=100)\n",
    "\n",
    "Y_train_tensor_p1 = df_train.pop('price')\n",
    "X_train = df_train\n",
    "\n",
    "Y_test_tensor_p1 = df_test.pop('price')\n",
    "X_test_batch = df_test\n",
    "X_train.head()\n",
    "\n",
    "\n",
    "b_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea']\n",
    "X_p3 = housing[b_vars]\n",
    "X_train_df_p3 = X_train[b_vars]\n",
    "X_test_df_p3 = X_test_batch[b_vars]\n",
    "\n",
    "X_train_tensor_p1 = X_train_df_p3.to_numpy()\n",
    "X_test_tensor_p1 = X_test_df_p3.to_numpy()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_tensor_p1)\n",
    "X_train_tensor_p1 = scaler.transform(X_train_tensor_p1)\n",
    "X_test_tensor_p1 = scaler.transform(X_test_tensor_p1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print(100 * (results1 - results2) / results1)\n",
    "        \n",
    "    def __init__(self, in_dim, out_dim, hidden_layers=[64,32], activation=nn.Tanh,):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        self.input_cols = []\n",
    "        self.output_cols = []\n",
    "        \n",
    "        #Error Mode is a 5 bit integer, with each bit representing a feature\n",
    "        # If the bit is 1, the feature is errored\n",
    "        output_features = out_dim\n",
    "        input_features = in_dim\n",
    "        \n",
    "\n",
    "        \n",
    "        self.stack_list = [nn.Linear(input_features, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])\n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], output_features)])\n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha=1e-2, loss_fn=nn.MSELoss(),):\n",
    "        \n",
    "        val_hist = np.zeros(epochs)\n",
    "        train_hist = np.zeros(epochs)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "        for i in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = self.forward(X_train)\n",
    "            loss = loss_fn(Y_pred.squeeze(), Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_hist[i] = np.sqrt(loss.item())\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                Y_pred_val = self.forward(X_test)\n",
    "                val_hist[i] = np.sqrt(loss_fn(Y_pred_val, Y_test).item())\n",
    "            \n",
    "        self.last_test = Y_test_tensor_p1\n",
    "        self.last_pred = self.forward(X_test)\n",
    "        self.last_score = val_hist[-1]\n",
    "        \n",
    "        self.last_epochs = epochs\n",
    "        self.last_val_hist = val_hist\n",
    "        self.last_train_hist = train_hist\n",
    "    \n",
    "    def plot_loss(self, title):\n",
    "        \n",
    "        plt.plot(range(self.last_epochs), self.last_val_hist, label='Validation Loss')\n",
    "        plt.plot(range(self.last_epochs), self.last_train_hist, label='Training Loss')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMS Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    \n",
    "    def print_results(self):\n",
    "        if self.last_score is None:\n",
    "            raise ValueError('No results to print')\n",
    "        print(f'MSE: {self.last_score:.2E}')\n",
    "        \n",
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self, lambda_val=0.0):\n",
    "        super(CustomMSELoss, self).__init__()\n",
    "        self.lambda_val = lambda_val\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "\n",
    "        m = targets.size(0)\n",
    "        \n",
    "        errors = predictions - targets\n",
    "        mse_loss = (1 / (2*m)) * torch.sum(errors ** 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        total_loss = mse_loss\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaskin/.local/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([436, 1])) that is different to the input size (torch.Size([436])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.09E+06\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "\n",
    "X_train_tensor_p1 = torch.tensor(X_train_tensor_p1).to(device).float()\n",
    "X_test_tensor_p1 = torch.tensor(X_test_tensor_p1).to(device).float()\n",
    "\n",
    "Y_train_tensor_p1 = torch.tensor(Y_train_tensor_p1.to_numpy()).to(device).float().view(-1, 1)\n",
    "Y_test_tensor_p1 = torch.tensor(Y_test_tensor_p1.to_numpy()).to(device).float().view(-1, 1)\n",
    "\n",
    "\n",
    "model_1a = Regressor(\n",
    "    in_dim=X_train_tensor_p1.shape[1],\n",
    "    out_dim=1,\n",
    "    hidden_layers=[8],\n",
    "    activation=nn.ReLU,\n",
    ").to(device)\n",
    "\n",
    "model_1a.train(\n",
    "    epochs=5000,\n",
    "    X_train=X_train_tensor_p1,\n",
    "    X_test=X_test_tensor_p1,\n",
    "    Y_train=Y_train_tensor_p1,\n",
    "    Y_test=Y_test_tensor_p1,\n",
    "    alpha=1e-1,\n",
    "    loss_fn=nn.MSELoss(),\n",
    ")\n",
    "\n",
    "model_1a.plot_loss('Problem 1a: 1 Hidden Layer Loss')\n",
    "model_1a.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "X_2 = breast.data\n",
    "Y_2 = breast.target\n",
    "\n",
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(X_2, Y_2, train_size=0.8, test_size=0.2, random_state=00)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_2)\n",
    "X_train_2 = scaler.transform(X_train_2)\n",
    "X_test_2 = scaler.transform(X_test_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print('Comparing results:')\n",
    "        comparisons = {\n",
    "            'accuracy': 100*(results1['accuracy'] - results2['accuracy'])/results1['accuracy'],\n",
    "            'precision': 100*(results1['precision'] - results2['precision'])/results1['precision'],\n",
    "            'recall': 100*(results1['recall'] - results2['recall'])/results1['recall'],\n",
    "            'f1': 100*(results1['f1'] - results2['f1'])/results1['f1']\n",
    "        }\n",
    "        for key, value in comparisons.items():\n",
    "            print(f'{key}: {value} %')\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "            \n",
    "        if isinstance(Y_test, torch.Tensor):\n",
    "            Y_test = Y_test.cpu().detach().numpy()\n",
    "        if isinstance(Y_pred, torch.Tensor):\n",
    "            Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        results = {\n",
    "            'accuracy': accuracy_score(Y_test, Y_pred),\n",
    "            'precision': precision_score(Y_test, Y_pred, average='weighted'),\n",
    "            'recall': recall_score(Y_test, Y_pred, average='weighted'),\n",
    "            'f1': f1_score(Y_test, Y_pred, average='weighted'),\n",
    "            'confusion_matrix': confusion_matrix(Y_test, Y_pred),\n",
    "            'classification_report': classification_report(Y_test, Y_pred)\n",
    "        }\n",
    "        self.last_results = results\n",
    "        return results\n",
    "    def print_results(self, results=None):\n",
    "        if results is None:\n",
    "            try: \n",
    "                results = self.last_results\n",
    "            except:\n",
    "                results = self.get_results()\n",
    "        for key, value in results.items():\n",
    "            if key in ['confusion_matrix', 'classification_report']:\n",
    "                print(f'{key.capitalize()}:\\n{value}')\n",
    "            else:\n",
    "                print(f'{key.capitalize()}: {value}')\n",
    "                \n",
    "    \n",
    "class LogisticClassifier(Classifier):        \n",
    "    def __init__(self, input_dim=0, activation=nn.ReLU, hidden_layers = [64, 32, 16], pass_through=False):\n",
    "        super().__init__()\n",
    "        if pass_through:\n",
    "            return\n",
    "        self.stack_list = [nn.Linear(input_dim, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])  \n",
    "        \n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], 1), nn.Sigmoid()]) \n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x).round()\n",
    "    \n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha, loss_fn=nn.BCELoss(), print_epoch=500):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=alpha)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = self.forward(X_train)\n",
    "            loss = loss_fn(Y_pred, Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % print_epoch == 0:\n",
    "                test_loss = loss_fn(self.forward(X_test), Y_test)\n",
    "                print(f'Epoch {epoch}: Training Loss: {loss.item()}, Test Loss: {test_loss.item()}')\n",
    "        Y_pred = self.predict(X_test)\n",
    "        self.last_pred = Y_pred\n",
    "        self.last_test = Y_test\n",
    "        return [Y_test,Y_pred]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 0.6775199174880981, Test Loss: 0.6508200168609619\n",
      "Epoch 500: Training Loss: 0.05119786411523819, Test Loss: 0.08860453963279724\n",
      "Epoch 1000: Training Loss: 0.03805161640048027, Test Loss: 0.09681770205497742\n",
      "Epoch 1500: Training Loss: 0.029710467904806137, Test Loss: 0.10133590549230576\n",
      "Epoch 2000: Training Loss: 0.023742537945508957, Test Loss: 0.09929131716489792\n",
      "Epoch 2500: Training Loss: 0.018893906846642494, Test Loss: 0.09738191962242126\n",
      "Epoch 3000: Training Loss: 0.015220258384943008, Test Loss: 0.09081994742155075\n",
      "Epoch 3500: Training Loss: 0.012455631978809834, Test Loss: 0.08439692854881287\n",
      "Epoch 4000: Training Loss: 0.010189911350607872, Test Loss: 0.07659681141376495\n",
      "Epoch 4500: Training Loss: 0.008512535132467747, Test Loss: 0.06754373759031296\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.9657164890247598\n",
      "Recall: 0.9649122807017544\n",
      "F1: 0.965011961722488\n",
      "Confusion_matrix:\n",
      "[[46  1]\n",
      " [ 3 64]]\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96        47\n",
      "         1.0       0.98      0.96      0.97        67\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_2 = torch.tensor(X_train_2).to(device).float()\n",
    "X_test_2 = torch.tensor(X_test_2).to(device).float()\n",
    "Y_train_2 = torch.tensor(Y_train_2).to(device).float().view(-1, 1)\n",
    "Y_test_2 = torch.tensor(Y_test_2).to(device).float().view(-1, 1)\n",
    "\n",
    "model_2a = LogisticClassifier(\n",
    "    input_dim=X_train_2.shape[1],\n",
    "    hidden_layers=[32],\n",
    "    activation=nn.ReLU\n",
    ").to(device)\n",
    "\n",
    "model_2a.train(\n",
    "    epochs=5000,\n",
    "    X_train=X_train_2,\n",
    "    X_test=X_test_2,\n",
    "    Y_train=Y_train_2,\n",
    "    Y_test=Y_test_2,\n",
    "    alpha=1e-1,\n",
    "    loss_fn=nn.BCELoss(),\n",
    "    print_epoch=500\n",
    ")\n",
    "\n",
    "results_2a = model_2a.get_results()\n",
    "model_2a.print_results(results_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 0.7006031274795532, Test Loss: 0.6969746351242065\n",
      "Epoch 500: Training Loss: 0.0444357804954052, Test Loss: 0.09696567803621292\n",
      "Epoch 1000: Training Loss: 0.023338234052062035, Test Loss: 0.0965108647942543\n",
      "Epoch 1500: Training Loss: 0.01155084278434515, Test Loss: 0.09876886010169983\n",
      "Epoch 2000: Training Loss: 0.0062743364833295345, Test Loss: 0.1080765500664711\n",
      "Epoch 2500: Training Loss: 0.0038169343024492264, Test Loss: 0.11713045835494995\n",
      "Epoch 3000: Training Loss: 0.0025181507226079702, Test Loss: 0.12493595480918884\n",
      "Epoch 3500: Training Loss: 0.0017743278294801712, Test Loss: 0.13145829737186432\n",
      "Epoch 4000: Training Loss: 0.001317627727985382, Test Loss: 0.1369219720363617\n",
      "Epoch 4500: Training Loss: 0.00102024688385427, Test Loss: 0.1416374146938324\n",
      "\n",
      "\n",
      "Accuracy: 0.9473684210526315\n",
      "Precision: 0.9502514456074828\n",
      "Recall: 0.9473684210526315\n",
      "F1: 0.9476328183095101\n",
      "Confusion_matrix:\n",
      "[[46  1]\n",
      " [ 5 62]]\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94        47\n",
      "         1.0       0.98      0.93      0.95        67\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2b = LogisticClassifier(\n",
    "    input_dim=X_train_2.shape[1],\n",
    "    hidden_layers=[32,64,32],\n",
    "    activation=nn.ReLU\n",
    ").to(device)\n",
    "\n",
    "model_2b.train(\n",
    "    epochs=5000,\n",
    "    X_train=X_train_2,\n",
    "    X_test=X_test_2,\n",
    "    Y_train=Y_train_2,\n",
    "    Y_test=Y_test_2,\n",
    "    alpha=5e-2,\n",
    "    loss_fn=nn.BCELoss(),\n",
    "    print_epoch=500\n",
    ")\n",
    "print('\\n')\n",
    "results_2b = model_2b.get_results()\n",
    "model_2b.print_results(results_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Import cifar-10 dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = './data'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_imgs = torch.stack([img for img, _ in cifar10], dim=3)\n",
    "view = train_imgs.view(3, -1)#.to(device=device)\n",
    "\n",
    "mean = train_imgs.view(3, -1).mean(dim=1)\n",
    "std = train_imgs.view(3, -1).std(dim=1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(cifar10_train, batch_size=64, shuffle=True)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=64, shuffle=False)\n",
    "X_test_3 = torch.stack([img for img, _ in cifar10_test], dim=3).view(3, -1).to(device=device)\n",
    "Y_test_3 = torch.tensor([label for _, label in cifar10_test]).to(device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class ImageClassifier(Classifier):\n",
    "    def __init__(self, input_dim=0, output_dim = 0, activation=nn.ReLU, hidden_layers = [64, 32, 16], pass_through=False):\n",
    "        super().__init__()\n",
    "        self.stack_list = [nn.Flatten(), nn.Linear(input_dim, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])  \n",
    "        \n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], output_dim), nn.Softmax(dim=1)])\n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x).argmax(dim=1)\n",
    "    def train_model(\n",
    "        self,\n",
    "        epochs,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        alpha,\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.SGD,\n",
    "        print_epoch=10,\n",
    "    ):\n",
    "        \n",
    "        optimizer = optimizer(self.parameters(), lr=alpha)\n",
    "        training_time = 0\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_loss = 0\n",
    "            for X_batch, Y_batch in train_loader:\n",
    "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                Y_pred = self.forward(X_batch)\n",
    "                loss = loss_fn(Y_pred, Y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            training_time += time.time() - start_time\n",
    "            \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                Y_pred_eval = []\n",
    "                Y_test = []\n",
    "                for X_test_batch, Y_test_batch in test_loader:\n",
    "                    X_test_batch, Y_test_batch = X_test_batch.to(device), Y_test_batch.to(device)\n",
    "                    \n",
    "                    out = self.forward(X_test_batch)\n",
    "                    test_loss += loss_fn(out, Y_test_batch).item()\n",
    "                    Y_test.extend(Y_test_batch.cpu().detach().numpy())\n",
    "                    Y_pred_eval.extend(out.argmax(dim=1).cpu().detach().numpy())\n",
    "                \n",
    "            accuracy = accuracy_score(Y_test, Y_pred_eval)\n",
    "            if epoch % print_epoch == 0:\n",
    "                print(f'Epoch {epoch}: Training Loss: {train_loss/len(train_loader)}, Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "        self.last_pred = torch.tensor(Y_pred_eval)\n",
    "        self.last_test = torch.tensor(Y_test)\n",
    "        print(f'\\nTraining Time: {training_time} seconds\\n')\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 2.201410284737492, Test Loss: 2.1488690786300952, Accuracy: 0.3354\n",
      "Epoch 1: Training Loss: 2.1313129562855986, Test Loss: 2.115134690217911, Accuracy: 0.3624\n",
      "Epoch 2: Training Loss: 2.1072356914315384, Test Loss: 2.097880730963057, Accuracy: 0.3769\n",
      "Epoch 3: Training Loss: 2.0923693166364488, Test Loss: 2.086663885481039, Accuracy: 0.3865\n",
      "Epoch 4: Training Loss: 2.08120296205706, Test Loss: 2.077612098614881, Accuracy: 0.3979\n",
      "Epoch 5: Training Loss: 2.0715074409609255, Test Loss: 2.070352053945991, Accuracy: 0.4042\n",
      "Epoch 6: Training Loss: 2.0632094161589736, Test Loss: 2.064615787973829, Accuracy: 0.4078\n",
      "Epoch 7: Training Loss: 2.0561082657340846, Test Loss: 2.0597093469777685, Accuracy: 0.4105\n",
      "Epoch 8: Training Loss: 2.0497846004298275, Test Loss: 2.054938104501955, Accuracy: 0.4137\n",
      "Epoch 9: Training Loss: 2.0441966700127057, Test Loss: 2.0527782402220804, Accuracy: 0.415\n",
      "Epoch 10: Training Loss: 2.0390897987748655, Test Loss: 2.048685533225916, Accuracy: 0.4202\n",
      "Epoch 11: Training Loss: 2.034578595319977, Test Loss: 2.0454648467385845, Accuracy: 0.4231\n",
      "Epoch 12: Training Loss: 2.0302584508190984, Test Loss: 2.0433450481694218, Accuracy: 0.4246\n",
      "Epoch 13: Training Loss: 2.02627748418647, Test Loss: 2.0410740231252777, Accuracy: 0.4278\n",
      "Epoch 14: Training Loss: 2.0223188958204616, Test Loss: 2.038747470090344, Accuracy: 0.4294\n",
      "Epoch 15: Training Loss: 2.018991274144643, Test Loss: 2.037671606252148, Accuracy: 0.4305\n",
      "Epoch 16: Training Loss: 2.0157555367635642, Test Loss: 2.035060773229903, Accuracy: 0.4328\n",
      "Epoch 17: Training Loss: 2.0125163214285964, Test Loss: 2.032249483333272, Accuracy: 0.4377\n",
      "Epoch 18: Training Loss: 2.0089872252300878, Test Loss: 2.0313054520613067, Accuracy: 0.4373\n",
      "Epoch 19: Training Loss: 2.006210855053514, Test Loss: 2.030170185550763, Accuracy: 0.4373\n",
      "Epoch 20: Training Loss: 2.0031930728031853, Test Loss: 2.0274508234801565, Accuracy: 0.4399\n",
      "Epoch 21: Training Loss: 2.000550609567891, Test Loss: 2.026248433787352, Accuracy: 0.4396\n",
      "Epoch 22: Training Loss: 1.9977973473956212, Test Loss: 2.02506713502726, Accuracy: 0.441\n",
      "Epoch 23: Training Loss: 1.9950800313973975, Test Loss: 2.0247168244829603, Accuracy: 0.4403\n",
      "Epoch 24: Training Loss: 1.9924540940453024, Test Loss: 2.0225466793509805, Accuracy: 0.4421\n",
      "Epoch 25: Training Loss: 1.990202148552136, Test Loss: 2.021040697006663, Accuracy: 0.4442\n",
      "Epoch 26: Training Loss: 1.9875995176832388, Test Loss: 2.02035410009372, Accuracy: 0.4446\n",
      "Epoch 27: Training Loss: 1.9850812461370093, Test Loss: 2.018848002336587, Accuracy: 0.4461\n",
      "Epoch 28: Training Loss: 1.982587840093676, Test Loss: 2.0185956916991312, Accuracy: 0.4447\n",
      "Epoch 29: Training Loss: 1.9802616491647023, Test Loss: 2.017457759304411, Accuracy: 0.447\n",
      "Epoch 30: Training Loss: 1.977693507585989, Test Loss: 2.0163778438689604, Accuracy: 0.4484\n",
      "Epoch 31: Training Loss: 1.975706407633584, Test Loss: 2.0154311193782055, Accuracy: 0.4482\n",
      "Epoch 32: Training Loss: 1.9732406907679174, Test Loss: 2.014418176025342, Accuracy: 0.4508\n",
      "Epoch 33: Training Loss: 1.9709903735029117, Test Loss: 2.0140721251250833, Accuracy: 0.4491\n",
      "Epoch 34: Training Loss: 1.968823590394481, Test Loss: 2.0130390232535684, Accuracy: 0.4507\n",
      "Epoch 35: Training Loss: 1.9664480809665397, Test Loss: 2.0122012309967334, Accuracy: 0.4499\n",
      "Epoch 36: Training Loss: 1.964585790853671, Test Loss: 2.0116470315653805, Accuracy: 0.4507\n",
      "Epoch 37: Training Loss: 1.9623820021024445, Test Loss: 2.0096353451917124, Accuracy: 0.4548\n",
      "Epoch 38: Training Loss: 1.9603788617931668, Test Loss: 2.0097902701918486, Accuracy: 0.454\n",
      "Epoch 39: Training Loss: 1.958145472704602, Test Loss: 2.0092169615873106, Accuracy: 0.4545\n",
      "Epoch 40: Training Loss: 1.9559663636300264, Test Loss: 2.0086839882431518, Accuracy: 0.4548\n",
      "Epoch 41: Training Loss: 1.9539883107785374, Test Loss: 2.0087792797453083, Accuracy: 0.4545\n",
      "Epoch 42: Training Loss: 1.9520726197820795, Test Loss: 2.007216927352225, Accuracy: 0.4554\n",
      "Epoch 43: Training Loss: 1.9498786005522588, Test Loss: 2.0065962007850597, Accuracy: 0.4567\n",
      "Epoch 44: Training Loss: 1.9478924571705596, Test Loss: 2.0057929359423885, Accuracy: 0.4583\n",
      "Epoch 45: Training Loss: 1.9459039570425478, Test Loss: 2.0053204077823907, Accuracy: 0.457\n",
      "Epoch 46: Training Loss: 1.9441391784516746, Test Loss: 2.0043849876731823, Accuracy: 0.4595\n",
      "Epoch 47: Training Loss: 1.9421423170572656, Test Loss: 2.0044837848396058, Accuracy: 0.4594\n",
      "Epoch 48: Training Loss: 1.94016695022583, Test Loss: 2.002669891734032, Accuracy: 0.4619\n",
      "Epoch 49: Training Loss: 1.9382048354429358, Test Loss: 2.002578695868231, Accuracy: 0.4605\n",
      "Epoch 50: Training Loss: 1.9363141062924318, Test Loss: 2.0038897072433666, Accuracy: 0.4596\n",
      "Epoch 51: Training Loss: 1.9344832413946575, Test Loss: 2.0018469095230103, Accuracy: 0.4612\n",
      "Epoch 52: Training Loss: 1.9324918358832064, Test Loss: 2.0017270867232306, Accuracy: 0.4616\n",
      "Epoch 53: Training Loss: 1.9307439822675017, Test Loss: 2.001353355729656, Accuracy: 0.4633\n",
      "Epoch 54: Training Loss: 1.928962046685426, Test Loss: 2.0016647691179994, Accuracy: 0.4608\n",
      "Epoch 55: Training Loss: 1.927043501068564, Test Loss: 1.9999224835899985, Accuracy: 0.4651\n",
      "Epoch 56: Training Loss: 1.9250040407985678, Test Loss: 1.9994656105709683, Accuracy: 0.4641\n",
      "Epoch 57: Training Loss: 1.9234034970898153, Test Loss: 1.9991518092003597, Accuracy: 0.4642\n",
      "Epoch 58: Training Loss: 1.9215860725058924, Test Loss: 1.999201297000715, Accuracy: 0.4643\n",
      "Epoch 59: Training Loss: 1.9198868384446635, Test Loss: 1.9987571254657333, Accuracy: 0.4647\n",
      "Epoch 60: Training Loss: 1.9179791044396208, Test Loss: 1.9974228773906733, Accuracy: 0.4659\n",
      "Epoch 61: Training Loss: 1.916289828469991, Test Loss: 1.9975098523364705, Accuracy: 0.4673\n",
      "Epoch 62: Training Loss: 1.9146924146910762, Test Loss: 1.9978118755255536, Accuracy: 0.4662\n",
      "Epoch 63: Training Loss: 1.912617788137987, Test Loss: 1.9964036083525154, Accuracy: 0.4676\n",
      "Epoch 64: Training Loss: 1.9110569766415355, Test Loss: 1.995940009499811, Accuracy: 0.468\n",
      "Epoch 65: Training Loss: 1.9095145576750225, Test Loss: 1.9957442184922043, Accuracy: 0.4668\n",
      "Epoch 66: Training Loss: 1.9077311972218096, Test Loss: 1.995925371813926, Accuracy: 0.469\n",
      "Epoch 67: Training Loss: 1.906208941698684, Test Loss: 1.995034005231918, Accuracy: 0.4691\n",
      "Epoch 68: Training Loss: 1.9042365439712543, Test Loss: 1.9958832036158083, Accuracy: 0.4686\n",
      "Epoch 69: Training Loss: 1.9026686892180187, Test Loss: 1.994063199705379, Accuracy: 0.4693\n",
      "Epoch 70: Training Loss: 1.9011069923410635, Test Loss: 1.9941022388494698, Accuracy: 0.4689\n",
      "Epoch 71: Training Loss: 1.89944163963313, Test Loss: 1.9938461734990405, Accuracy: 0.4708\n",
      "Epoch 72: Training Loss: 1.8979422139084858, Test Loss: 1.9931916909612668, Accuracy: 0.4695\n",
      "Epoch 73: Training Loss: 1.8962264480188376, Test Loss: 1.9930588234761717, Accuracy: 0.4729\n",
      "Epoch 74: Training Loss: 1.894419810503645, Test Loss: 1.9929505951085669, Accuracy: 0.4722\n",
      "Epoch 75: Training Loss: 1.8932654946051595, Test Loss: 1.9926604366606209, Accuracy: 0.469\n",
      "Epoch 76: Training Loss: 1.8913014256740774, Test Loss: 1.9919216412647514, Accuracy: 0.4722\n",
      "Epoch 77: Training Loss: 1.8898866644600774, Test Loss: 1.9922871020189516, Accuracy: 0.4712\n",
      "Epoch 78: Training Loss: 1.8885408505759276, Test Loss: 1.9918207097205387, Accuracy: 0.4715\n",
      "Epoch 79: Training Loss: 1.8867450173553604, Test Loss: 1.9917527133492148, Accuracy: 0.4733\n",
      "Epoch 80: Training Loss: 1.885162004424483, Test Loss: 1.9901161619052765, Accuracy: 0.4739\n",
      "Epoch 81: Training Loss: 1.8836467884995443, Test Loss: 1.990831255153486, Accuracy: 0.4749\n",
      "Epoch 82: Training Loss: 1.8821341834409768, Test Loss: 1.9903806865594948, Accuracy: 0.4735\n",
      "Epoch 83: Training Loss: 1.880492230053143, Test Loss: 1.9894001423173648, Accuracy: 0.4761\n",
      "Epoch 84: Training Loss: 1.8792056093740341, Test Loss: 1.9900260746099387, Accuracy: 0.474\n",
      "Epoch 85: Training Loss: 1.877844167030071, Test Loss: 1.9894564698456199, Accuracy: 0.4731\n",
      "Epoch 86: Training Loss: 1.876429661765428, Test Loss: 1.9892730614182297, Accuracy: 0.4771\n",
      "Epoch 87: Training Loss: 1.8750434484323273, Test Loss: 1.9887491677217424, Accuracy: 0.476\n",
      "Epoch 88: Training Loss: 1.8735629942106165, Test Loss: 1.9892685428546493, Accuracy: 0.4746\n",
      "Epoch 89: Training Loss: 1.8719964249969443, Test Loss: 1.9882509078189825, Accuracy: 0.4746\n",
      "Epoch 90: Training Loss: 1.8706222033256765, Test Loss: 1.987908758175601, Accuracy: 0.4747\n",
      "Epoch 91: Training Loss: 1.869113135063435, Test Loss: 1.9885168736148033, Accuracy: 0.476\n",
      "Epoch 92: Training Loss: 1.8677857948081267, Test Loss: 1.988387291598472, Accuracy: 0.4748\n",
      "Epoch 93: Training Loss: 1.8664771082151272, Test Loss: 1.9878002739256355, Accuracy: 0.475\n",
      "Epoch 94: Training Loss: 1.8650445026509903, Test Loss: 1.9875242808821854, Accuracy: 0.4747\n",
      "Epoch 95: Training Loss: 1.8636897526433707, Test Loss: 1.9874323697606469, Accuracy: 0.475\n",
      "Epoch 96: Training Loss: 1.8621286147695673, Test Loss: 1.9872268529454613, Accuracy: 0.4757\n",
      "Epoch 97: Training Loss: 1.8607349558864408, Test Loss: 1.9873499710848377, Accuracy: 0.4763\n",
      "Epoch 98: Training Loss: 1.859359428248442, Test Loss: 1.986620311524458, Accuracy: 0.4745\n",
      "Epoch 99: Training Loss: 1.8583002029477482, Test Loss: 1.986218580015146, Accuracy: 0.4742\n",
      "\n",
      "Training Time: 1157.4642927646637 seconds\n",
      "\n",
      "Accuracy: 0.4742\n",
      "Precision: 0.46611456870171314\n",
      "Recall: 0.4742\n",
      "F1: 0.4682781879764696\n",
      "Confusion_matrix:\n",
      "[[587  37  61  25  20  17  24  36 137  56]\n",
      " [ 34 561  26  39  21  23  41  38  77 140]\n",
      " [105  37 289  78 141  69 143  69  42  27]\n",
      " [ 37  37  93 271  65 163 149  61  42  82]\n",
      " [ 50  25 128  58 394  57 116 111  31  30]\n",
      " [ 29  28 100 156  80 348  92  84  50  33]\n",
      " [ 11  24  58  70 127  63 563  29  25  30]\n",
      " [ 45  37  54  50  85  76  42 518  25  68]\n",
      " [ 89  58  16  24  13  28  14  20 681  57]\n",
      " [ 64 158  15  28  16  26  49  42  72 530]]\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57      1000\n",
      "           1       0.56      0.56      0.56      1000\n",
      "           2       0.34      0.29      0.31      1000\n",
      "           3       0.34      0.27      0.30      1000\n",
      "           4       0.41      0.39      0.40      1000\n",
      "           5       0.40      0.35      0.37      1000\n",
      "           6       0.46      0.56      0.50      1000\n",
      "           7       0.51      0.52      0.52      1000\n",
      "           8       0.58      0.68      0.62      1000\n",
      "           9       0.50      0.53      0.52      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.47      0.47      0.47     10000\n",
      "weighted avg       0.47      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_3a = ImageClassifier(\n",
    "    input_dim=3*32*32,\n",
    "    output_dim=10,\n",
    "    hidden_layers=[256],\n",
    "    activation=nn.Tanh\n",
    ").to(device)\n",
    "\n",
    "model_3a.train_model(\n",
    "    epochs=100,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    alpha=1e-2,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    print_epoch=1\n",
    ")\n",
    "\n",
    "model_3a.get_results()\n",
    "model_3a.print_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4742\n",
      "Precision: 0.46611456870171314\n",
      "Recall: 0.4742\n",
      "F1: 0.4682781879764696\n",
      "Confusion_matrix:\n",
      "[[587  37  61  25  20  17  24  36 137  56]\n",
      " [ 34 561  26  39  21  23  41  38  77 140]\n",
      " [105  37 289  78 141  69 143  69  42  27]\n",
      " [ 37  37  93 271  65 163 149  61  42  82]\n",
      " [ 50  25 128  58 394  57 116 111  31  30]\n",
      " [ 29  28 100 156  80 348  92  84  50  33]\n",
      " [ 11  24  58  70 127  63 563  29  25  30]\n",
      " [ 45  37  54  50  85  76  42 518  25  68]\n",
      " [ 89  58  16  24  13  28  14  20 681  57]\n",
      " [ 64 158  15  28  16  26  49  42  72 530]]\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57      1000\n",
      "           1       0.56      0.56      0.56      1000\n",
      "           2       0.34      0.29      0.31      1000\n",
      "           3       0.34      0.27      0.30      1000\n",
      "           4       0.41      0.39      0.40      1000\n",
      "           5       0.40      0.35      0.37      1000\n",
      "           6       0.46      0.56      0.50      1000\n",
      "           7       0.51      0.52      0.52      1000\n",
      "           8       0.58      0.68      0.62      1000\n",
      "           9       0.50      0.53      0.52      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.47      0.47      0.47     10000\n",
      "weighted avg       0.47      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3a_results = model_3a.get_results()\n",
    "model_3a.print_results(model_3a_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed the SGD optimizer is much slower than Adam, but yields more consistent results. To improve the model performance, the alpha was increased to 1e-2 to deal with the lower learning rate of SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 2.280403497273965, Test Loss: 2.252564680804113, Accuracy: 0.2359\n",
      "Epoch 1: Training Loss: 2.228228701045141, Test Loss: 2.202385954036834, Accuracy: 0.2707\n",
      "Epoch 2: Training Loss: 2.1879612088508313, Test Loss: 2.172818032039958, Accuracy: 0.2915\n",
      "Epoch 3: Training Loss: 2.164266648804745, Test Loss: 2.152656055559778, Accuracy: 0.316\n",
      "Epoch 4: Training Loss: 2.145001944983402, Test Loss: 2.1356226805668728, Accuracy: 0.3354\n",
      "Epoch 5: Training Loss: 2.128756971615355, Test Loss: 2.1195827631434057, Accuracy: 0.3519\n",
      "Epoch 6: Training Loss: 2.113841903484081, Test Loss: 2.107796171668229, Accuracy: 0.3608\n",
      "Epoch 7: Training Loss: 2.1028579657949753, Test Loss: 2.098387276291088, Accuracy: 0.371\n",
      "Epoch 8: Training Loss: 2.0934950303848443, Test Loss: 2.090748143803542, Accuracy: 0.3772\n",
      "Epoch 9: Training Loss: 2.0848870728631765, Test Loss: 2.084034829382684, Accuracy: 0.3808\n",
      "Epoch 10: Training Loss: 2.0770044459406374, Test Loss: 2.078609412642801, Accuracy: 0.3871\n",
      "Epoch 11: Training Loss: 2.070014102532126, Test Loss: 2.0740907898374425, Accuracy: 0.391\n",
      "Epoch 12: Training Loss: 2.0636268466939707, Test Loss: 2.0721085997903423, Accuracy: 0.3919\n",
      "Epoch 13: Training Loss: 2.0574979936070457, Test Loss: 2.0637668682511445, Accuracy: 0.3985\n",
      "Epoch 14: Training Loss: 2.051519621058803, Test Loss: 2.0614985918543143, Accuracy: 0.4013\n",
      "Epoch 15: Training Loss: 2.046250664821976, Test Loss: 2.056406200311746, Accuracy: 0.4054\n",
      "Epoch 16: Training Loss: 2.0412039791836456, Test Loss: 2.053648417163047, Accuracy: 0.4074\n",
      "Epoch 17: Training Loss: 2.036012465539186, Test Loss: 2.049658063111032, Accuracy: 0.4128\n",
      "Epoch 18: Training Loss: 2.031437578561056, Test Loss: 2.0488287567333052, Accuracy: 0.4131\n",
      "Epoch 19: Training Loss: 2.0267347254411643, Test Loss: 2.0439856819286466, Accuracy: 0.4178\n",
      "Epoch 20: Training Loss: 2.022114611952506, Test Loss: 2.043041490445471, Accuracy: 0.4191\n",
      "Epoch 21: Training Loss: 2.017402906704437, Test Loss: 2.038575057011501, Accuracy: 0.4234\n",
      "Epoch 22: Training Loss: 2.0128561633322244, Test Loss: 2.0373852860396076, Accuracy: 0.4235\n",
      "Epoch 23: Training Loss: 2.0082216503675028, Test Loss: 2.0335943714068954, Accuracy: 0.4275\n",
      "Epoch 24: Training Loss: 2.0037876928553864, Test Loss: 2.030826511656403, Accuracy: 0.4319\n",
      "Epoch 25: Training Loss: 1.9994239329986865, Test Loss: 2.0289009050199183, Accuracy: 0.4343\n",
      "Epoch 26: Training Loss: 1.9945184483247644, Test Loss: 2.0266629237278253, Accuracy: 0.4382\n",
      "Epoch 27: Training Loss: 1.9897202751825533, Test Loss: 2.0271820012171555, Accuracy: 0.437\n",
      "Epoch 28: Training Loss: 1.9846469432191776, Test Loss: 2.0247295221705346, Accuracy: 0.4392\n",
      "Epoch 29: Training Loss: 1.9798921794842577, Test Loss: 2.0211990319999162, Accuracy: 0.4406\n",
      "Epoch 30: Training Loss: 1.975139911522341, Test Loss: 2.019865758859428, Accuracy: 0.4439\n",
      "Epoch 31: Training Loss: 1.970379686569009, Test Loss: 2.0177729889086096, Accuracy: 0.4455\n",
      "Epoch 32: Training Loss: 1.9653151279215313, Test Loss: 2.015972366758213, Accuracy: 0.446\n",
      "Epoch 33: Training Loss: 1.9602141008352685, Test Loss: 2.0135348678394487, Accuracy: 0.4484\n",
      "Epoch 34: Training Loss: 1.9551919712434949, Test Loss: 2.011253961332285, Accuracy: 0.4515\n",
      "Epoch 35: Training Loss: 1.950315807481556, Test Loss: 2.0147219919095374, Accuracy: 0.4458\n",
      "Epoch 36: Training Loss: 1.9453664797041423, Test Loss: 2.0082669774438164, Accuracy: 0.4536\n",
      "Epoch 37: Training Loss: 1.940512748782897, Test Loss: 2.009062681987787, Accuracy: 0.4502\n",
      "Epoch 38: Training Loss: 1.9353905344558189, Test Loss: 2.009172895152098, Accuracy: 0.4531\n",
      "Epoch 39: Training Loss: 1.9309233869128215, Test Loss: 2.0051034256151525, Accuracy: 0.457\n",
      "Epoch 40: Training Loss: 1.9258459394850085, Test Loss: 2.0054075057339515, Accuracy: 0.4542\n",
      "Epoch 41: Training Loss: 1.920948523389714, Test Loss: 2.0034787070219684, Accuracy: 0.4572\n",
      "Epoch 42: Training Loss: 1.9158197467589317, Test Loss: 2.003737722232843, Accuracy: 0.4566\n",
      "Epoch 43: Training Loss: 1.9112602746700083, Test Loss: 2.007011801573881, Accuracy: 0.45\n",
      "Epoch 44: Training Loss: 1.9068707323745084, Test Loss: 2.003478769284145, Accuracy: 0.4543\n",
      "Epoch 45: Training Loss: 1.90230433227461, Test Loss: 2.00412516609119, Accuracy: 0.4558\n",
      "Epoch 46: Training Loss: 1.8979026368816796, Test Loss: 2.0014274537942973, Accuracy: 0.4565\n",
      "Epoch 47: Training Loss: 1.8929194580868383, Test Loss: 2.005838249139725, Accuracy: 0.4531\n",
      "Epoch 48: Training Loss: 1.8888147938281983, Test Loss: 2.0037533644657985, Accuracy: 0.4546\n",
      "Epoch 49: Training Loss: 1.8840698384872787, Test Loss: 2.0042982344414777, Accuracy: 0.4539\n",
      "Epoch 50: Training Loss: 1.8803379241462863, Test Loss: 2.0060581659815115, Accuracy: 0.4536\n",
      "Epoch 51: Training Loss: 1.8755995143405007, Test Loss: 2.0026044678536192, Accuracy: 0.4558\n",
      "Epoch 52: Training Loss: 1.8712224228607723, Test Loss: 1.9998929014631137, Accuracy: 0.4587\n",
      "Epoch 53: Training Loss: 1.8668004260648547, Test Loss: 2.0050053262406853, Accuracy: 0.4537\n",
      "Epoch 54: Training Loss: 1.862304040080751, Test Loss: 1.9967357801024321, Accuracy: 0.4616\n",
      "Epoch 55: Training Loss: 1.8581476738995604, Test Loss: 2.011644670158435, Accuracy: 0.4476\n",
      "Epoch 56: Training Loss: 1.85449959600673, Test Loss: 2.0013837252452875, Accuracy: 0.4555\n",
      "Epoch 57: Training Loss: 1.8503952450154688, Test Loss: 2.005105645793259, Accuracy: 0.4534\n",
      "Epoch 58: Training Loss: 1.8461702011735237, Test Loss: 2.0121096296674885, Accuracy: 0.4455\n",
      "Epoch 59: Training Loss: 1.8425086915035687, Test Loss: 2.00076228418168, Accuracy: 0.4561\n",
      "Epoch 60: Training Loss: 1.8384573668470163, Test Loss: 1.9964367902962266, Accuracy: 0.4612\n",
      "Epoch 61: Training Loss: 1.834525834568931, Test Loss: 1.9943766305401067, Accuracy: 0.4647\n",
      "Epoch 62: Training Loss: 1.8304467589958855, Test Loss: 1.9952366450789627, Accuracy: 0.4618\n",
      "Epoch 63: Training Loss: 1.8265629633308371, Test Loss: 2.0005740686586706, Accuracy: 0.456\n",
      "Epoch 64: Training Loss: 1.822805018223765, Test Loss: 2.005883834923908, Accuracy: 0.4491\n",
      "Epoch 65: Training Loss: 1.81961776914499, Test Loss: 1.99604929632442, Accuracy: 0.4605\n",
      "Epoch 66: Training Loss: 1.8148655074331768, Test Loss: 1.9966157560895204, Accuracy: 0.4607\n",
      "Epoch 67: Training Loss: 1.8123863682417614, Test Loss: 2.001093756621051, Accuracy: 0.4567\n",
      "Epoch 68: Training Loss: 1.8089882707047036, Test Loss: 1.9976130207632756, Accuracy: 0.4591\n",
      "Epoch 69: Training Loss: 1.8050172597246097, Test Loss: 2.000473508409634, Accuracy: 0.4585\n",
      "Epoch 70: Training Loss: 1.8015150918680078, Test Loss: 1.9935544228098194, Accuracy: 0.4642\n",
      "Epoch 71: Training Loss: 1.798106653458627, Test Loss: 1.9967582954722605, Accuracy: 0.459\n",
      "Epoch 72: Training Loss: 1.7946201843373917, Test Loss: 1.9966439912273626, Accuracy: 0.4595\n",
      "Epoch 73: Training Loss: 1.7911296585941558, Test Loss: 1.9975928455401377, Accuracy: 0.4605\n",
      "Epoch 74: Training Loss: 1.7893220724352181, Test Loss: 1.9976800953506664, Accuracy: 0.4607\n",
      "Epoch 75: Training Loss: 1.7857283984913546, Test Loss: 1.997754140264669, Accuracy: 0.461\n",
      "Epoch 76: Training Loss: 1.7820604012140533, Test Loss: 2.0081516086675557, Accuracy: 0.4476\n",
      "Epoch 77: Training Loss: 1.7795437854879044, Test Loss: 2.014743470841912, Accuracy: 0.442\n",
      "Epoch 78: Training Loss: 1.7772340364468373, Test Loss: 1.9949941035288914, Accuracy: 0.4622\n",
      "Epoch 79: Training Loss: 1.774098057423711, Test Loss: 2.003993206722721, Accuracy: 0.4537\n",
      "Epoch 80: Training Loss: 1.771172871979911, Test Loss: 1.996228008513238, Accuracy: 0.4629\n",
      "Epoch 81: Training Loss: 1.7697991905614847, Test Loss: 1.998249265039043, Accuracy: 0.4581\n",
      "Epoch 82: Training Loss: 1.7668739221894834, Test Loss: 2.0033721316392255, Accuracy: 0.4551\n",
      "Epoch 83: Training Loss: 1.7646816086281292, Test Loss: 1.9957349505394129, Accuracy: 0.4613\n",
      "Epoch 84: Training Loss: 1.7610802517827515, Test Loss: 1.9970971710363012, Accuracy: 0.4589\n",
      "Epoch 85: Training Loss: 1.7594040022481738, Test Loss: 1.995714901359218, Accuracy: 0.4591\n",
      "Epoch 86: Training Loss: 1.7561884853236205, Test Loss: 2.000106747742671, Accuracy: 0.4548\n",
      "Epoch 87: Training Loss: 1.7541905739118375, Test Loss: 1.9980947082969034, Accuracy: 0.4594\n",
      "Epoch 88: Training Loss: 1.752043614302145, Test Loss: 1.9978720876061993, Accuracy: 0.4585\n",
      "Epoch 89: Training Loss: 1.7497063177016081, Test Loss: 2.04112223758819, Accuracy: 0.4134\n",
      "Epoch 90: Training Loss: 1.7477915985200105, Test Loss: 1.9977301518628552, Accuracy: 0.4571\n",
      "Epoch 91: Training Loss: 1.745197372515793, Test Loss: 2.0041657192691877, Accuracy: 0.4528\n",
      "Epoch 92: Training Loss: 1.7442166652825788, Test Loss: 1.998430759284147, Accuracy: 0.4579\n",
      "Epoch 93: Training Loss: 1.7417706339560506, Test Loss: 2.000380478087504, Accuracy: 0.4567\n",
      "Epoch 94: Training Loss: 1.7388503150561887, Test Loss: 2.007878496388721, Accuracy: 0.4491\n",
      "Epoch 95: Training Loss: 1.7377261348697535, Test Loss: 2.003134667493735, Accuracy: 0.4536\n",
      "Epoch 96: Training Loss: 1.7351144726014198, Test Loss: 2.000657352672261, Accuracy: 0.4562\n",
      "Epoch 97: Training Loss: 1.7338576975380977, Test Loss: 2.0077067985656156, Accuracy: 0.4488\n",
      "Epoch 98: Training Loss: 1.7315342722036648, Test Loss: 2.003403690969868, Accuracy: 0.4531\n",
      "Epoch 99: Training Loss: 1.730216651621377, Test Loss: 2.002178602917179, Accuracy: 0.4532\n",
      "\n",
      "Training Time: 1186.6000225543976 seconds\n",
      "\n",
      "Accuracy: 0.4742\n",
      "Precision: 0.46611456870171314\n",
      "Recall: 0.4742\n",
      "F1: 0.4682781879764696\n",
      "Confusion_matrix:\n",
      "[[587  37  61  25  20  17  24  36 137  56]\n",
      " [ 34 561  26  39  21  23  41  38  77 140]\n",
      " [105  37 289  78 141  69 143  69  42  27]\n",
      " [ 37  37  93 271  65 163 149  61  42  82]\n",
      " [ 50  25 128  58 394  57 116 111  31  30]\n",
      " [ 29  28 100 156  80 348  92  84  50  33]\n",
      " [ 11  24  58  70 127  63 563  29  25  30]\n",
      " [ 45  37  54  50  85  76  42 518  25  68]\n",
      " [ 89  58  16  24  13  28  14  20 681  57]\n",
      " [ 64 158  15  28  16  26  49  42  72 530]]\n",
      "Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57      1000\n",
      "           1       0.56      0.56      0.56      1000\n",
      "           2       0.34      0.29      0.31      1000\n",
      "           3       0.34      0.27      0.30      1000\n",
      "           4       0.41      0.39      0.40      1000\n",
      "           5       0.40      0.35      0.37      1000\n",
      "           6       0.46      0.56      0.50      1000\n",
      "           7       0.51      0.52      0.52      1000\n",
      "           8       0.58      0.68      0.62      1000\n",
      "           9       0.50      0.53      0.52      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.47      0.47      0.47     10000\n",
      "weighted avg       0.47      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_3b = ImageClassifier(\n",
    "    input_dim=3*32*32,\n",
    "    output_dim=10,\n",
    "    hidden_layers=[256,512,128],#[256,384,256],\n",
    "    activation=nn.Tanh\n",
    ").to(device)\n",
    "\n",
    "model_3b.train_model(\n",
    "    epochs=100,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    alpha=1e-2,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer = torch.optim.SGD,\n",
    "    print_epoch=1\n",
    ")\n",
    "\n",
    "model_3b_results = model_3a.get_results()\n",
    "model_3b.print_results(model_3a_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
