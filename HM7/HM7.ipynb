{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from datetime import datetime\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_imgs = torch.stack([img for img, _ in cifar10], dim=3)\n",
    "view = train_imgs.view(3, -1)#.to(device=device)\n",
    "\n",
    "mean = train_imgs.view(3, -1).mean(dim=1)\n",
    "std = train_imgs.view(3, -1).std(dim=1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(cifar10_train, batch_size=64, shuffle=True)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=64, shuffle=False)\n",
    "X_test_3 = torch.stack([img for img, _ in cifar10_test], dim=3).view(3, -1).to(device=device)\n",
    "Y_test_3 = torch.tensor([label for _, label in cifar10_test]).to(device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print('Comparing results:')\n",
    "        comparisons = {\n",
    "            'accuracy': 100*(results1['accuracy'] - results2['accuracy'])/results1['accuracy'],\n",
    "            'precision': 100*(results1['precision'] - results2['precision'])/results1['precision'],\n",
    "            'recall': 100*(results1['recall'] - results2['recall'])/results1['recall'],\n",
    "            'f1': 100*(results1['f1'] - results2['f1'])/results1['f1']\n",
    "        }\n",
    "        for key, value in comparisons.items():\n",
    "            print(f'{key}: {value} %')\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "            \n",
    "        if isinstance(Y_test, torch.Tensor):\n",
    "            Y_test = Y_test.cpu().detach().numpy()\n",
    "        if isinstance(Y_pred, torch.Tensor):\n",
    "            Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        results = {\n",
    "            'accuracy': accuracy_score(Y_test, Y_pred),\n",
    "            'precision': precision_score(Y_test, Y_pred, average='weighted'),\n",
    "            'recall': recall_score(Y_test, Y_pred, average='weighted'),\n",
    "            'f1': f1_score(Y_test, Y_pred, average='weighted'),\n",
    "            'confusion_matrix': confusion_matrix(Y_test, Y_pred),\n",
    "            'classification_report': classification_report(Y_test, Y_pred)\n",
    "        }\n",
    "        self.last_results = results\n",
    "        return results\n",
    "    def print_results(self, results=None):\n",
    "        if results is None:\n",
    "            try: \n",
    "                results = self.last_results\n",
    "            except:\n",
    "                results = self.get_results()\n",
    "        for key, value in results.items():\n",
    "            if key in ['confusion_matrix', 'classification_report']:\n",
    "                print(f'{key.capitalize()}:\\n{value}')\n",
    "            else:\n",
    "                print(f'{key.capitalize()}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu0): ReLU()\n",
       "  (maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc0): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (relu_fc1): ReLU()\n",
       "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 32\n",
    "conv_layers = [16, 8]\n",
    "fc_layers = [32, 10]\n",
    "\n",
    "stack = nn.Sequential(OrderedDict(\n",
    "    [\n",
    "        ('conv0', nn.Conv2d(in_channels=3, out_channels=conv_layers[0], kernel_size=3, padding=1)),\n",
    "        ('relu0', nn.ReLU()),\n",
    "        ('maxpool0', nn.MaxPool2d(2)),\n",
    "    ]\n",
    "))\n",
    "\n",
    "for i in range(1, len(conv_layers)):\n",
    "    stack.add_module(f'conv{i}', nn.Conv2d(in_channels=conv_layers[i-1], out_channels=conv_layers[i], kernel_size=3, padding=1))\n",
    "    stack.add_module(f'relu{i}', nn.ReLU())\n",
    "    stack.add_module(f'maxpool{i}', nn.MaxPool2d(2))\n",
    "    \n",
    "conv_out = input_dim//(2**len(conv_layers))\n",
    "stack.add_module('flatten', nn.Flatten())\n",
    "stack.add_module(f'fc0', nn.Linear(conv_out**2*conv_layers[-1], fc_layers[0]))\n",
    "\n",
    "for i in range(1, len(fc_layers)):\n",
    "    stack.add_module(f'relu_fc{i}', nn.ReLU())\n",
    "    stack.add_module(f'fc{i}', nn.Linear(fc_layers[i-1], fc_layers[i]))        \n",
    "\n",
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvImageClassifier(Classifier):\n",
    "    def __init__(self, input_dim, conv_layers, fc_layers, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stack = nn.Sequential(OrderedDict(\n",
    "            [\n",
    "                ('conv0', nn.Conv2d(in_channels=3, out_channels=conv_layers[0], kernel_size=3, padding=1)),\n",
    "                ('activation0', activation()),\n",
    "                ('maxpool0', nn.MaxPool2d(2)),\n",
    "            ]\n",
    "        ))\n",
    "        \n",
    "        for i in range(1, len(conv_layers)):\n",
    "            self.stack.add_module(f'conv{i}', nn.Conv2d(in_channels=conv_layers[i-1], out_channels=conv_layers[i], kernel_size=3, padding=1))\n",
    "            self.stack.add_module(f'activation{i}', activation())\n",
    "            self.stack.add_module(f'maxpool{i}', nn.MaxPool2d(2))\n",
    "            \n",
    "        conv_out = input_dim//(2**len(conv_layers))\n",
    "        self.stack.add_module('flatten', nn.Flatten())\n",
    "        self.stack.add_module(f'fc0', nn.Linear(conv_out**2*conv_layers[-1], fc_layers[0]))\n",
    "        \n",
    "        for i in range(1, len(fc_layers)):\n",
    "            self.stack.add_module(f'activation_fc{i}', activation())\n",
    "            self.stack.add_module(f'fc{i}', nn.Linear(fc_layers[i-1], fc_layers[i]))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x).argmax(dim=1)\n",
    "    def train_model(\n",
    "        self,\n",
    "        epochs,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        alpha,\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.SGD,\n",
    "        print_epoch=10,\n",
    "    ):  \n",
    "        optimizer = optimizer(self.parameters(), lr=alpha)\n",
    "        training_time = 0\n",
    "        train_hist = np.zeros(epochs)\n",
    "        test_hist = np.zeros(epochs)\n",
    "        accuracy_hist = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            begin_epoch = time.time()\n",
    "            self.train()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_loss = 0\n",
    "            for X_batch, Y_batch in train_loader:\n",
    "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                Y_pred = self.forward(X_batch)\n",
    "                loss = loss_fn(Y_pred, Y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            training_time += time.time() - start_time\n",
    "            train_hist[epoch] = train_loss/len(train_loader)\n",
    "            \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                Y_pred_eval = []\n",
    "                Y_test = []\n",
    "                for X_test_batch, Y_test_batch in test_loader:\n",
    "                    X_test_batch, Y_test_batch = X_test_batch.to(device), Y_test_batch.to(device)\n",
    "                    \n",
    "                    out = self.forward(X_test_batch)\n",
    "                    test_loss += loss_fn(out, Y_test_batch).item()\n",
    "                    Y_test.extend(Y_test_batch.cpu().detach().numpy())\n",
    "                    Y_pred_eval.extend(out.argmax(dim=1).cpu().detach().numpy())\n",
    "                \n",
    "            test_hist[epoch] = test_loss/len(test_loader)\n",
    "            accuracy_hist[epoch] = accuracy_score(Y_test, Y_pred_eval)\n",
    "            if epoch % print_epoch == 0 or epoch == epochs - 1:\n",
    "                end_epoch = time.time()\n",
    "                print(f'Epoch {epoch}: Training Loss: {train_hist[epoch]}, Test Loss: {test_hist[epoch]}, Accuracy: {accuracy_hist[epoch]}, Epoch Duration: {(end_epoch - begin_epoch):2f} seconds')\n",
    "        self.last_pred = torch.tensor(Y_pred_eval)\n",
    "        self.last_test = torch.tensor(Y_test)\n",
    "        print(f'\\nTraining Time: {training_time} seconds\\n')\n",
    "        \n",
    "        self.train_hist = train_hist\n",
    "        self.test_hist = test_hist\n",
    "        self.accuracy_hist = accuracy_hist\n",
    "    \n",
    "    def plot_training(self, title='Training Results'):\n",
    "        plt.plot(self.train_hist, label='Training Loss')\n",
    "        plt.plot(self.test_hist, label='Test Loss')\n",
    "        plt.plot(self.accuracy_hist, label='Accuracy')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation0): ReLU()\n",
      "  (maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc0): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (activation_fc1): ReLU()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 0: Training Loss: 2.3024880873882556, Test Loss: 2.2893322030450127, Accuracy: 0.1102, Epoch Duration: 14.603000 seconds\n",
      "Epoch 1: Training Loss: 2.273302452643509, Test Loss: 2.253652671340165, Accuracy: 0.1615, Epoch Duration: 14.198816 seconds\n"
     ]
    }
   ],
   "source": [
    "model_1a = ConvImageClassifier(\n",
    "    input_dim = 32,\n",
    "    conv_layers=[16, 8],\n",
    "    fc_layers=[32, 10],\n",
    "    activation=nn.ReLU\n",
    ").to(device=device)\n",
    "\n",
    "print(model_1a.stack)\n",
    "\n",
    "model_1a.train_model(\n",
    "    epochs=200,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    alpha=1e-3,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    print_epoch=1\n",
    ")\n",
    "\n",
    "model_1a.get_results()\n",
    "model_1a.print_results()\n",
    "model_1a.plot_training(\"Problem 1a Training Curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
