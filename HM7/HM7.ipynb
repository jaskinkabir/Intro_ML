{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from datetime import datetime\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = False\n",
    "data_path = './data'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=dl, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_imgs = torch.stack([img for img, _ in cifar10], dim=3)#.to(device=device)\n",
    "view = train_imgs.view(3, -1)#.to(device=device)\n",
    "\n",
    "mean = train_imgs.view(3, -1).mean(dim=1)\n",
    "std = train_imgs.view(3, -1).std(dim=1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print('Comparing results:')\n",
    "        comparisons = {\n",
    "            'accuracy': 100*(results1['accuracy'] - results2['accuracy'])/results1['accuracy'],\n",
    "            'precision': 100*(results1['precision'] - results2['precision'])/results1['precision'],\n",
    "            'recall': 100*(results1['recall'] - results2['recall'])/results1['recall'],\n",
    "            'f1': 100*(results1['f1'] - results2['f1'])/results1['f1']\n",
    "        }\n",
    "        for key, value in comparisons.items():\n",
    "            print(f'{key}: {value} %')\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "            \n",
    "        if isinstance(Y_test, torch.Tensor):\n",
    "            Y_test = Y_test.cpu().detach().numpy()\n",
    "        if isinstance(Y_pred, torch.Tensor):\n",
    "            Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        results = {\n",
    "            'accuracy': accuracy_score(Y_test, Y_pred),\n",
    "            'precision': precision_score(Y_test, Y_pred, average='weighted'),\n",
    "            'recall': recall_score(Y_test, Y_pred, average='weighted'),\n",
    "            'f1': f1_score(Y_test, Y_pred, average='weighted'),\n",
    "            'confusion_matrix': confusion_matrix(Y_test, Y_pred),\n",
    "            'classification_report': classification_report(Y_test, Y_pred)\n",
    "        }\n",
    "        self.last_results = results\n",
    "        return results\n",
    "    def print_results(self, results=None):\n",
    "        if results is None:\n",
    "            try: \n",
    "                results = self.last_results\n",
    "            except:\n",
    "                results = self.get_results()\n",
    "        for key, value in results.items():\n",
    "            if key in ['confusion_matrix', 'classification_report']:\n",
    "                print(f'{key.capitalize()}:\\n{value}')\n",
    "            else:\n",
    "                print(f'{key.capitalize()}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvImageClassifier(Classifier):\n",
    "    def __init__(self, input_dim, conv_layers, fc_layers, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stack = nn.Sequential(OrderedDict(\n",
    "            [\n",
    "                ('conv0', nn.Conv2d(in_channels=3, out_channels=conv_layers[0], kernel_size=3, padding=1)),\n",
    "                ('activation0', activation()),\n",
    "                ('maxpool0', nn.MaxPool2d(2)),\n",
    "            ]\n",
    "        ))\n",
    "        \n",
    "        for i in range(1, len(conv_layers)):\n",
    "            self.stack.add_module(f'conv{i}', nn.Conv2d(in_channels=conv_layers[i-1], out_channels=conv_layers[i], kernel_size=3, padding=1))\n",
    "            self.stack.add_module(f'activation{i}', activation())\n",
    "            self.stack.add_module(f'maxpool{i}', nn.MaxPool2d(2))\n",
    "            \n",
    "        conv_out = input_dim//(2**len(conv_layers))\n",
    "        self.stack.add_module('flatten', nn.Flatten())\n",
    "        self.stack.add_module(f'fc0', nn.Linear(conv_out**2*conv_layers[-1], fc_layers[0]))\n",
    "        \n",
    "        for i in range(1, len(fc_layers)):\n",
    "            self.stack.add_module(f'activation_fc{i}', activation())\n",
    "            self.stack.add_module(f'fc{i}', nn.Linear(fc_layers[i-1], fc_layers[i]))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x).argmax(dim=1)\n",
    "    def train_model(\n",
    "        self,\n",
    "        epochs,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.SGD,\n",
    "        optimizer_args = [],\n",
    "        optimizer_kwargs = {},\n",
    "        print_epoch=10,\n",
    "        header_epoch = 15\n",
    "    ):  \n",
    "        optimizer = optimizer(self.parameters(), *optimizer_args, **optimizer_kwargs)\n",
    "        training_time = 0\n",
    "        train_hist = np.zeros(epochs)\n",
    "        test_hist = np.zeros(epochs)\n",
    "        accuracy_hist = np.zeros(epochs)\n",
    "        \n",
    "        cell_width = 15\n",
    "        header_form_spec = f'^{cell_width}'\n",
    "        header_string = f\"|{'Epoch':{header_form_spec}}|{'Epoch Time (s)':{header_form_spec}}|{'Training Loss':{header_form_spec}}|{'Test Loss ':{header_form_spec}}|{'Overfit (%)':{header_form_spec}}|{'Accuracy (%)':{header_form_spec}}|\"\n",
    "        divider_string = '-'*(cell_width*6 + 7)\n",
    "        if print_epoch:\n",
    "            print(f'Training {self.__class__.__name__}\\n')\n",
    "            print(divider_string)\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            begin_epoch = time.time()\n",
    "            self.train()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_loss = 0\n",
    "            for X_batch, Y_batch in train_loader:\n",
    "                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "                Y_pred = self.forward(X_batch)\n",
    "                loss = loss_fn(Y_pred, Y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            training_time += time.time() - start_time\n",
    "            train_loss = train_loss/len(train_loader)\n",
    "            train_hist[epoch] = train_loss\n",
    "            \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                correct = 0               \n",
    "                \n",
    "                for X_test_batch, Y_test_batch in test_loader:\n",
    "                    X_test_batch, Y_test_batch = X_test_batch.to(device, non_blocking=True), Y_test_batch.to(device, non_blocking=True)\n",
    "                    \n",
    "                    out = self.forward(X_test_batch)\n",
    "                    test_loss += loss_fn(out, Y_test_batch).detach()\n",
    "                    correct += (out.argmax(dim=1) == Y_test_batch).sum()\n",
    "                    \n",
    "            test_loss = test_loss/len(test_loader)\n",
    "            test_hist[epoch] = test_loss\n",
    "            accuracy = correct/len(cifar10_test)\n",
    "            accuracy_hist[epoch] = accuracy\n",
    "            end_epoch = time.time()\n",
    "            if print_epoch and (epoch % print_epoch == 0 or epoch == epochs - 1) :\n",
    "                if header_epoch and epoch % header_epoch == 0:\n",
    "                    print(header_string)\n",
    "                    print(divider_string)\n",
    "                epoch_duration = end_epoch - begin_epoch\n",
    "                overfit = 100 * (test_loss - train_loss) / train_loss\n",
    "                print(f\"|{epoch:^{cell_width}}|{epoch_duration:^{cell_width}.5f}|{train_loss:^{cell_width}.8f}|{test_loss:^{cell_width}.8f}|{overfit:^{cell_width}.5f}|{accuracy:^{cell_width}.5f}|\")\n",
    "                print(divider_string)\n",
    "\n",
    "        print(f'\\nTraining Time: {training_time} seconds\\n')\n",
    "        \n",
    "        self.train_hist = train_hist\n",
    "        self.test_hist = test_hist\n",
    "        self.accuracy_hist = accuracy_hist\n",
    "    \n",
    "    def plot_training(self, title='Training Results'):\n",
    "        plt.plot(self.train_hist, label='Training Loss')\n",
    "        plt.plot(self.test_hist, label='Test Loss')\n",
    "        plt.plot(self.accuracy_hist, label='Accuracy')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation0): ReLU()\n",
      "  (maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc0): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (activation_fc1): ReLU()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Training ConvImageClassifier\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|     Epoch     |  Epoch Time   | Training Loss |  Test Loss    |    Overfit    |   Accuracy    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       0       |    5.90268    |  2.18386550   |  2.01502895   |   -7.73109    |    0.29660    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       1       |    4.24075    |  1.90770118   |  1.79847813   |   -5.72537    |    0.36540    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       2       |    4.12749    |  1.73773584   |  1.68150115   |   -3.23609    |    0.40870    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       3       |    4.04380    |  1.63505352   |  1.59427798   |   -2.49383    |    0.44120    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       4       |    3.91809    |  1.55964353   |  1.52307832   |   -2.34446    |    0.46190    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       5       |    3.96254    |  1.49694403   |  1.47920132   |   -1.18526    |    0.47410    |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|       6       |    4.67092    |  1.45467759   |  1.43394566   |   -1.42519    |    0.49210    |\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Batch size of 64 surprisingly gave the best results\n",
    "workers = 16\n",
    "cifar10_train = datasets.CIFAR10(data_path, train=True, download=dl, transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    cifar10_train,\n",
    "    batch_size=2048,\n",
    "    shuffle=True,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(data_path, train=False, download=dl, transform=transform)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=len(cifar10_test), shuffle=True, num_workers=workers, pin_memory=True, prefetch_factor=4)\n",
    "\n",
    "model_1a = ConvImageClassifier(\n",
    "    input_dim = 32,\n",
    "    conv_layers=[16, 8],\n",
    "    fc_layers=[32, 10],\n",
    "    activation=nn.ReLU\n",
    ").to(device=device)\n",
    " \n",
    "print(model_1a.stack)\n",
    "\n",
    "model_1a.train_model(\n",
    "    epochs=200,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer_kwargs={'lr': 1e-3, 'weight_decay': 1e-3},\n",
    "    print_epoch=1,\n",
    "    header_epoch=15\n",
    ")\n",
    "\n",
    "model_1a.plot_training(\"2 Layer CNN Training Curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation0): ReLU()\n",
      "  (maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (activation1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc0): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (activation_fc1): ReLU()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 0.8791261120718352, Test Loss: 1.0047351121902466, Accuracy: 0.6539, Epoch Duration: 3.084385 seconds\n",
      "Epoch 1: Training Loss: 0.8790079294418802, Test Loss: 1.0044175386428833, Accuracy: 0.6536, Epoch Duration: 2.741097 seconds\n",
      "Epoch 2: Training Loss: 0.8790595494970983, Test Loss: 1.0054110288619995, Accuracy: 0.6532, Epoch Duration: 2.818763 seconds\n",
      "Epoch 3: Training Loss: 0.8791011206957758, Test Loss: 1.00322687625885, Accuracy: 0.653, Epoch Duration: 2.878485 seconds\n",
      "Epoch 4: Training Loss: 0.8786848491551925, Test Loss: 1.0035338401794434, Accuracy: 0.6533, Epoch Duration: 2.799796 seconds\n",
      "Epoch 5: Training Loss: 0.8785350991755115, Test Loss: 1.0045143365859985, Accuracy: 0.6528, Epoch Duration: 2.849511 seconds\n",
      "Epoch 6: Training Loss: 0.8786300724866439, Test Loss: 1.0064029693603516, Accuracy: 0.6533, Epoch Duration: 2.837314 seconds\n",
      "Epoch 7: Training Loss: 0.8787848158758513, Test Loss: 1.0045053958892822, Accuracy: 0.6538, Epoch Duration: 2.745900 seconds\n",
      "Epoch 8: Training Loss: 0.87875319743643, Test Loss: 1.003534197807312, Accuracy: 0.6538, Epoch Duration: 2.824438 seconds\n",
      "Epoch 9: Training Loss: 0.8786006144114903, Test Loss: 1.003336787223816, Accuracy: 0.6527, Epoch Duration: 2.902532 seconds\n",
      "Epoch 10: Training Loss: 0.8785022497177124, Test Loss: 1.0034945011138916, Accuracy: 0.6527, Epoch Duration: 2.828430 seconds\n",
      "Epoch 11: Training Loss: 0.8784166002760128, Test Loss: 1.0073814392089844, Accuracy: 0.6534, Epoch Duration: 2.834753 seconds\n",
      "Epoch 12: Training Loss: 0.8785107427713822, Test Loss: 1.0037784576416016, Accuracy: 0.6543, Epoch Duration: 2.776026 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fcabbc43e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss: 0.8782890730974625, Test Loss: 1.002672553062439, Accuracy: 0.6524, Epoch Duration: 2.658063 seconds\n",
      "Epoch 14: Training Loss: 0.8782460957157369, Test Loss: 1.0027246475219727, Accuracy: 0.6521, Epoch Duration: 2.761882 seconds\n",
      "Epoch 15: Training Loss: 0.8782481624155628, Test Loss: 1.0009883642196655, Accuracy: 0.6529, Epoch Duration: 2.920649 seconds\n",
      "Epoch 16: Training Loss: 0.8782350250652858, Test Loss: 1.006370186805725, Accuracy: 0.6528, Epoch Duration: 2.849427 seconds\n",
      "Epoch 17: Training Loss: 0.8781948661317631, Test Loss: 1.0020439624786377, Accuracy: 0.6528, Epoch Duration: 2.829332 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fcabbc43e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss: 0.878077219943611, Test Loss: 1.004275918006897, Accuracy: 0.6535, Epoch Duration: 3.030113 seconds\n",
      "Epoch 19: Training Loss: 0.8779937028884888, Test Loss: 1.0054913759231567, Accuracy: 0.6516, Epoch Duration: 2.836216 seconds\n",
      "Epoch 20: Training Loss: 0.8778746541665525, Test Loss: 1.0032696723937988, Accuracy: 0.6537, Epoch Duration: 2.963073 seconds\n",
      "Epoch 21: Training Loss: 0.8780069630973193, Test Loss: 1.0045653581619263, Accuracy: 0.652, Epoch Duration: 2.842553 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    cifar10_train,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=workers,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "model_1b = ConvImageClassifier(\n",
    "    input_dim = 32,\n",
    "    conv_layers=[16, 8,4],\n",
    "    fc_layers=[32, 10],\n",
    "    activation=nn.ReLU\n",
    ").to(device=device)\n",
    " \n",
    "print(model_1a.stack)\n",
    "\n",
    "model_1a.train_model(\n",
    "    epochs=200,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    alpha=1e-3,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    print_epoch=1\n",
    ")\n",
    "\n",
    "model_1a.plot_training(\"3 Layer CNN Training Curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
